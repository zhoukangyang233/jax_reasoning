training:
    batch_size: 512
    eval_batch_size: 512
    epochs: 2000
    log_per_epoch: 1
    eval_interval: 10
    checkpoint_interval: 10

    optimizer: adam_atan2

model:
    name: HRM_default

dataset:
    augmentations_per_puzzle: 255
    augmentation_refresh_interval: 1
