training:
    batch_size: 512
    eval_batch_size: 512
    epochs: 10000
    log_per_epoch: 1
    eval_interval: 50
    checkpoint_interval: 50

    optimizer: adam_atan2

model:
    name: HRM_default

dataset:
    augmentations_per_puzzle: 99
